{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import datetime\n",
    "import time\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.zip')\n",
    "df2 = pd.read_csv('kaggle_task.zip')\n",
    "df = df.append(df2, sort=False).reset_index(drop=True)[['URL_TA']]\n",
    "df['URL_TA_ind2'] = df['URL_TA'].apply(lambda x: x.split(\"-\")[2])\n",
    "df['parser_status'] = -9\n",
    "\n",
    "df['city_R1'] = \"\"\n",
    "df['city_R2'] = \"\"\n",
    "\n",
    "df['R_Food'] = 0\n",
    "df['R_Service'] = 0\n",
    "df['R_Value'] = 0\n",
    "df['R_Atmosphere'] = 0\n",
    "\n",
    "df['R5_Excellent'] = 0\n",
    "df['R4_Very_good'] = 0\n",
    "df['R3_Average'] = 0\n",
    "df['R2_Poor'] = 0\n",
    "df['R1_Terrible'] = 0\n",
    "\n",
    "HOST = 'https://www.tripadvisor.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url, params = None, doc_type = 'html.parser', time_sleep = 0): #'html.parser'  'lxml'\n",
    "    try:\n",
    "        res = requests.get(url, headers={'User-Agent': UserAgent().chrome}, params = params)\n",
    "        time.sleep(time_sleep) \n",
    "        if res.status_code == 200:\n",
    "            page = BeautifulSoup(res.content, doc_type)\n",
    "            return page\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def page_parser(page):\n",
    "    save_data = dict()\n",
    "    try:\n",
    "        data = page.find_all(class_='_3-W4EexF')\n",
    "        if data is not None:\n",
    "            for i in range(len(data)):\n",
    "                save_data['city_R' + str(i+1)] = data[i].text\n",
    "                if i == 1:\n",
    "                    break\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data = page.find_all(class_='jT_QMHn2')\n",
    "        pattern = re.compile(\"ui_bubble_rating bubble_(\\d*)\")\n",
    "        if data is not None:\n",
    "            for i in range(len(data)):\n",
    "                if data[i].text in ['Food','Service','Value','Atmosphere']:\n",
    "                    save_data['R_' + data[i].text] = pattern.findall(str(data[i].find(class_='_377onWB-')))[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data = page.find_all(class_=\"row_num is-shown-at-tablet\")\n",
    "        if data is not None:\n",
    "            if len(data) == 5:\n",
    "                save_data['R5_Excellent'] = data[0].text\n",
    "                save_data['R4_Very_good'] = data[1].text\n",
    "                save_data['R3_Average'] = data[2].text\n",
    "                save_data['R2_Poor'] = data[3].text\n",
    "                save_data['R1_Terrible'] = data[4].text\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    return save_data\n",
    "\n",
    "def iter_parser(df_index_range = []):\n",
    "    if df_index_range != []:\n",
    "        if isinstance(df_index_range, int):\n",
    "            df_index_range = [df_index_range]\n",
    "            \n",
    "        for index_ in df_index_range:\n",
    "            page = get_page(HOST + df['URL_TA'][index_])\n",
    "            if page is None:\n",
    "                df.loc[index_, 'parser_status'] = -1\n",
    "                continue\n",
    "            data_ = page_parser(page)\n",
    "            if data_ == {}:\n",
    "                df.loc[index_, 'parser_status'] = 0\n",
    "                continue\n",
    "            \n",
    "            df.loc[index_, 'parser_status'] = 1\n",
    "            try:\n",
    "                df.update(pd.DataFrame(data_, index = [index_]))\n",
    "            except:\n",
    "                df.loc[index_, 'parser_status'] = -2         \n",
    "            \n",
    "def pool_parser(index_ = 0):\n",
    "    page = get_page(HOST + df['URL_TA'][index_])\n",
    "    if page is None:\n",
    "        df.loc[index_, 'parser_status'] = -1\n",
    "        return \n",
    "\n",
    "    data_ = page_parser(page)\n",
    "    if data_ == {}:\n",
    "        df.loc[index_, 'parser_status'] = 0\n",
    "        return \n",
    "\n",
    "    df.loc[index_, 'parser_status'] = 1\n",
    "    try:        \n",
    "        df.update(pd.DataFrame(data_, index = [index_]))\n",
    "    except:\n",
    "        df.loc[index_, 'parser_status'] = -2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# iter_parser(df_index_range = 3) #df.shape[0]\n",
    "# df.to_csv('dop_feat_parser.zip', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  - start -  2020-07-27 11:24:40.884559  : 29.877257\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "part = 1000\n",
    "for i in range(10, 11):\n",
    "    start = datetime.datetime.now()\n",
    "    print(i,\" - start - \", start, \" : \", end = \"\")\n",
    "    pool = Pool(20)\n",
    "    results = pool.map(pool_parser, list(range(part*i, part*(i+1)))) #df.shape[0]\n",
    "    pool.terminate()\n",
    "    print((datetime.datetime.now() - start).total_seconds())\n",
    "    df[part*i: part*(i+1)].to_csv('dop_feat_parser_'+str(i)+'.zip', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 14)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dop = pd.read_csv('myparser_result\\dop_feat_parser_0.zip', index_col = 'Unnamed: 0')\n",
    "for i in range(1, 50):\n",
    "    df_part = pd.read_csv('myparser_result\\dop_feat_parser_' + str(i) + '.zip', index_col = 'Unnamed: 0')\n",
    "    df_dop = df_dop.append(df_part, sort=False)\n",
    "\n",
    "df_dop[\"city_R1\"].fillna(\"\",inplace = True)\n",
    "df_dop[\"city_R2\"].fillna(\"\",inplace = True)\n",
    "df_dop.R5_Excellent = df_dop.R5_Excellent.apply(lambda x: str(x).replace(\",\",\"\")).astype('int64')\n",
    "df_dop.R4_Very_good = df_dop.R4_Very_good.apply(lambda x: str(x).replace(\",\",\"\")).astype('int64')\n",
    "df_dop.R3_Average = df_dop.R3_Average.apply(lambda x: str(x).replace(\",\",\"\")).astype('int64')\n",
    "df_dop.R2_Poor = df_dop.R2_Poor.apply(lambda x: str(x).replace(\",\",\"\")).astype('int64')\n",
    "df_dop.R1_Terrible = df_dop.R1_Terrible.apply(lambda x: str(x).replace(\",\",\"\")).astype('int64')\n",
    "df_dop['parser_status'] = df_dop['parser_status'].apply(lambda x: 0 if x == -1 else x)\n",
    "\n",
    "df_dop['check'] = df_dop[df_dop.columns[5:]].sum(axis = 1)\n",
    "df_dop['parser_status'] = df_dop.apply(lambda x: 0 if x['check'] == 0 and x['parser_status'] == -9 \n",
    "                                       else x['parser_status'], axis = 1)\n",
    "df_dop['parser_status'] = df_dop.apply(lambda x: 1 if x['check'] != 0 and x['parser_status'] == -9 \n",
    "                                       else x['parser_status'], axis = 1)\n",
    "df_dop.drop(columns = ['check'], inplace = True)\n",
    "\n",
    "df_dop.to_csv('dop_feat_parser_fin.zip', index=True)\n",
    "\n",
    "df_dop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL_TA           0\n",
       "URL_TA_ind2      0\n",
       "parser_status    0\n",
       "city_R1          0\n",
       "city_R2          0\n",
       "R_Food           0\n",
       "R_Service        0\n",
       "R_Value          0\n",
       "R_Atmosphere     0\n",
       "R5_Excellent     0\n",
       "R4_Very_good     0\n",
       "R3_Average       0\n",
       "R2_Poor          0\n",
       "R1_Terrible      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dop.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
