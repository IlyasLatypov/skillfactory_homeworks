{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среда или требования к инференсу модели для вашего проекта могут быть устроены так, что потребуют реализации на другом языке программирования, отличном от Python. Например, если компания разрабатывает десктопное приложение, то для внедрения модели её потребуется «перевести» на Java или C++. Как это сделать?\n",
    "\n",
    "В таких случаях используется генерация файла формата PMML (Predictive Model Markup Language). \n",
    "\n",
    "Определение: PMML\n",
    "\n",
    "PMML — это XML-диалект, который используется для описания статистических моделей и моделей data science. PMML-совместимые приложения позволяют легко обмениваться моделями данных между собой. Разработка и внедрение PMML осуществляется IT-консорциумом Data Mining Group.\n",
    "\n",
    "На момент подготовки данного материала актуальная версия спецификации — 4.4. Подробнее с ней можно ознакомиться на официальном сайте.\n",
    "\n",
    "К сожалению, далеко не все библиотеки машинного обучения (в том числе sklearn) поддерживают возможность сохранения обученной модели в указанном формате. Хорошая новость заключается в том, что можно использовать сторонние библиотеки. Одной из самых популярных является Nyoka. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyoka import skl_to_pmml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "cols = load_diabetes()['feature_names']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pipe = Pipeline([  \n",
    "            ('Scaling', MinMaxScaler()),\n",
    "            ('Linear', LinearRegression())\n",
    "        ])\n",
    "# Тренировка пайплайна, включающего линейную модель и нормализацию признаков\n",
    "pipe.fit(X, y)\n",
    "# Сохраним пайплайн в формате pmml в файл pipe.pmml\n",
    "skl_to_pmml(pipeline=pipe, col_names=cols, pmml_f_name=\"pipe.pmml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы построили пайплайн обработки данных и обучили модель линейной регрессии. После чего с помощью функции skl_to_pmml сохранили модель в файл pipe.pmml. \n",
    "\n",
    "✍ Задание\n",
    "\n",
    "Откройте файл pipe.pmml  с помощью любого текстового редактора.\n",
    "\n",
    "Давайте рассмотрим его подробнее.\n",
    "\n",
    "→ Секция  <DataDictionary> содержит информацию о признаках, включая наименование и тип данных, используемых для построения модели. \n",
    "\n",
    "→ Секция <TransformationDictionary> содержит информацию о необходимых преобразованиях для каждого признака. Обратите внимание, что в этом блоке также содержится информация для трансформации. Так как мы использовали minMaxScaler(), то в файле записаны минимальное и максимальное значение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в файле содержится вся информация для того, чтобы пайплайн мог быть использован на любом языке программирования.\n",
    "\n",
    "В разработке моделей на основе нейронных сетей сегодня наиболее распространен формат ONNX (Open Neural Network Exchange).\n",
    "\n",
    "Определение: ONNX\n",
    "\n",
    "ONNX (Open Neural Network Exchange) — это открытый стандарт для обеспечения совместимости моделей машинного обучения. Он позволяет разработчикам искусственного интеллекта использовать модели с различными инфраструктурами, инструментами, средами исполнения и компиляторами.\n",
    "\n",
    "Стандарт поддерживается совместно компаниями Microsoft, Amazon, Facebook и другими партнерами как проект с открытым исходным кодом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Информация на будущее\n",
    "\n",
    "Часто стандарт ONNX и его библиотеки используют для конвертации из одного фреймворка в другой (например, из Pytorch в Tensorflow для использования в продакшне). Для конвертации различных фреймворков (не только DL) в формат ONNX и обратно существует ряд библиотек: \n",
    "\n",
    "- ONNX-Tensorflow\n",
    "- Tensorflow-ONNX\n",
    "- Keras-ONNX\n",
    "- Sklearn-ONNX\n",
    "- …и другие.\n",
    "\n",
    "Также в рамках стандарта ONNX есть инструмент ONNX-runtime. Он служит для ускорения инференса Python-моделей, а также инференса на других языках, например Java, C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13) (127, 13)\n",
      "sklearn model predict:\n",
      " [23.1903541  18.97985889 19.82548836 19.00126197  4.39524325 11.90230303\n",
      " 21.24870187 28.64449553 29.03550064 13.90644782  6.41422339 32.65356658\n",
      " 18.99884691 20.01569489 37.15275422 22.80485488 29.04529555 33.04200949\n",
      " 10.48602033 24.45472284 21.33069324 27.60222354 37.52118276 13.6113556\n",
      "  9.56442243 15.03368415 35.5975585  26.01017573 25.52430154 27.06321433\n",
      " 19.07680237 30.54746571 31.27561168 16.40132981 39.76707419 20.27263903\n",
      " 18.94934061 17.12210014 21.6262832  28.15101424 26.95292863 19.14352801\n",
      " 14.50664721 25.78075705 18.50460146 13.93439214 24.96593139 19.12431756\n",
      " 20.6780475   6.23807397 27.71460362 26.74617711 11.83361779 40.10855118\n",
      " 14.66523328 22.12023896 20.34305401 20.3786179  23.56685605 21.91582872\n",
      " 20.79748126 35.43123681 17.32592458 20.92077502 24.1674162  43.38199388\n",
      " 19.59747681 20.11624895 22.35462757 28.12506906 25.53832602 12.88949504\n",
      " 13.1552648  33.3092473  26.12666965 22.54135443 12.14404271 16.61972119\n",
      " 28.52703363 17.81932988 24.42637646 27.69824683 23.05296655 24.4402857\n",
      " 27.23233855 30.4210596  24.04718434 19.88744242 31.13160771 21.41108091\n",
      " 19.88680529 36.86501486 37.91625512 24.00513438 25.64874538 12.43967316\n",
      " 28.95074601  9.82709099 13.94593323 28.30721693 20.43657045 15.31547598\n",
      " 15.47748826 19.9406056  21.70074992 15.33999115 12.4014992  25.67993384\n",
      " 24.75824916 21.43766149 16.75630786 26.01764392 18.91613898 21.260363\n",
      "  8.95751196 24.86285128 14.20211854 28.98987716 18.37995946 20.40169618\n",
      " 17.11225855 24.55966354 24.81152897 36.53760221 14.72009878 33.43276192\n",
      " 21.59847763]\n",
      "onnx model predict:\n",
      " [23.190351  18.979858  19.825487  19.001259   4.395239  11.9023\n",
      " 21.2487    28.644491  29.035498  13.906446   6.414221  32.65357\n",
      " 18.998844  20.015694  37.152752  22.804852  29.045296  33.042007\n",
      " 10.486018  24.454721  21.330692  27.602219  37.521187  13.611357\n",
      "  9.564424  15.033682  35.597557  26.010174  25.5243    27.063213\n",
      " 19.076801  30.547466  31.275612  16.401329  39.76707   20.272642\n",
      " 18.949343  17.122097  21.62628   28.151012  26.952927  19.143528\n",
      " 14.506642  25.780756  18.504599  13.934391  24.965929  19.124313\n",
      " 20.678047   6.2380714 27.714602  26.746176  11.833615  40.108547\n",
      " 14.665232  22.120237  20.343056  20.378616  23.566854  21.915827\n",
      " 20.797482  35.431236  17.325922  20.920773  24.167416  43.381996\n",
      " 19.597473  20.116247  22.354626  28.125067  25.538322  12.889493\n",
      " 13.155264  33.309242  26.126667  22.541353  12.144042  16.61972\n",
      " 28.52703   17.819328  24.426376  27.698248  23.052965  24.440285\n",
      " 27.232338  30.42106   24.047182  19.887442  31.131605  21.41108\n",
      " 19.8868    36.865013  37.916252  24.005133  25.648743  12.439672\n",
      " 28.950743   9.827087  13.945932  28.307217  20.43657   15.315475\n",
      " 15.477488  19.940605  21.700748  15.339991  12.401495  25.679935\n",
      " 24.758247  21.43766   16.756308  26.017641  18.916138  21.26036\n",
      "  8.957512  24.862852  14.202119  28.989876  18.379957  20.401695\n",
      " 17.112255  24.559662  24.811527  36.537598  14.720098  33.432762\n",
      " 21.598475 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "\n",
    "# загружаем данные\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# обучаем модель\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# делаем инференс моделью на тесте\n",
    "test_pred = model.predict(X_test)\n",
    "print('sklearn model predict:\\n', test_pred)\n",
    "\n",
    "# конвертируем модель в onnx формат\n",
    "initial_type = [('float_input', FloatTensorType([None, 13]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# сохраняем модель в файл\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())\n",
    "\n",
    "# Делаем инференс через onnxruntime\n",
    "sess = rt.InferenceSession(\"model.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "test_pred_onnx = sess.run([label_name],\n",
    "                {input_name: X_test.astype(np.float32)})[0].reshape(-1)\n",
    "print('onnx model predict:\\n',test_pred_onnx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет: ONNX-runtime можно использовать для ускорения инференса — сравните время выполнения предиктов sklearn и ONNX-моделей:\n",
    "\n",
    "%timeit model.predict(X_test)<br />\n",
    "%timeit sess.run([label_name], {input_name: X_test.astype(np.float32)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
