{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "SPAM_col = collections.Counter()\n",
    "NOT_SPAM_col = collections.Counter()\n",
    "P_SPAM = collections.Counter()\n",
    "P_not_SPAM = collections.Counter()\n",
    "SPAM_count = 0 #накопелнное количество писем спама для обучения\n",
    "NOT_SPAM_count = 0 #накопленное количество писем неспама для обучения\n",
    "P_All_SPAM = 0.5 #вероятность спама писемь, начальное значение\n",
    "SPAM_word_count = 0 # накопелнное количество слов среди писем спама для обучения\n",
    "NOT_SPAM_word_count = 0 # накопелнное количество слов среди писем неспама для обучения\n",
    "SPAM = 0\n",
    "NOT_SPAM = 1\n",
    "SPAM_DICT = {SPAM: \"SPAM\", NOT_SPAM: \"NOT SPAM\"}\n",
    "min_word_len = 9 #минимальная длинна слова которое нужно учитывать, если 0 или 1 не влияет\n",
    "                # спама на русском языке 3, для писемь на английском языке 9 (гиперпараметр)\n",
    "    \n",
    "train_data = [  \n",
    "    ['Купите новое чистящее средство', SPAM],   \n",
    "    ['Купи мою новую книгу', SPAM],  \n",
    "    ['Подари себе новый телефон', SPAM],\n",
    "    ['Добро пожаловать и купите новый телевизор', SPAM],\n",
    "    ['Привет давно не виделись', NOT_SPAM], \n",
    "    ['Довезем до аэропорта из пригорода всего за 399 рублей', SPAM], \n",
    "    ['Добро пожаловать в Мой Круг', NOT_SPAM],  \n",
    "    ['Я все еще жду документы', NOT_SPAM],  \n",
    "    ['Приглашаем на конференцию Data Science', NOT_SPAM],\n",
    "    ['Потерял твой телефон напомни', NOT_SPAM],\n",
    "    ['Порадуй своего питомца новым костюмом', SPAM],\n",
    "] \n",
    "\n",
    "train_data2 = [  \n",
    "    [\"Развивай бизнес на дому с услугой 'Безлимитный Интернет'\", NOT_SPAM],   \n",
    "    ['Мы получили ваше сообщение о пропаже багажа и домашнего питомца в здании аэропорта. Конечно, нам жаль. Но что мы можем с этим сделать?', SPAM],  \n",
    "    ['Перезвони по номеру +799999999 в течение 6 секунд и выиграй миллион рублей!', SPAM],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dels(x):\n",
    "    return x.replace(\",\",\"\").replace(\"...\",\"\").replace(\".\",\"\").replace(\"'\",\"\").replace(\":\",\"\").replace(\";\",\"\").\\\n",
    "    replace(\"!\",\"\").replace(\"?\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"{\",\"\").\\\n",
    "    replace(\"}\",\"\").replace(\"|\",\"\").replace(\"NUMBER\",\"\").replace(\"URL\",\"\")\n",
    "\n",
    "def calculate_word_frequencies(body, label):\n",
    "    if label == SPAM:\n",
    "        SPAM_col[body] += 1\n",
    "    else:\n",
    "        NOT_SPAM_col[body] +=1\n",
    "\n",
    "def train(train_data_):\n",
    "    global SPAM_count, NOT_SPAM_count, P_All_SPAM\n",
    "    \n",
    "    SPAM_count += sum(1 for body, label in train_data_ if label == SPAM)\n",
    "    NOT_SPAM_count += sum(1 for body, label in train_data_ if label == NOT_SPAM)\n",
    "    \n",
    "    if SPAM_count + NOT_SPAM_count > 0:\n",
    "        P_All_SPAM = SPAM_count/(SPAM_count+NOT_SPAM_count)\n",
    "        \n",
    "    for body, label in train_data_:\n",
    "        body = dels(body)\n",
    "        for i in body.lower().split():\n",
    "            if len(i)>=min_word_len:\n",
    "                calculate_word_frequencies(i, label)        \n",
    "        \n",
    "def calculate_P_Bi_A(word, label):\n",
    "    \n",
    "    if SPAM_col[word] + NOT_SPAM_col[word] == 0:\n",
    "        SPAM_col[word] +=1\n",
    "        NOT_SPAM_col[word] +=1\n",
    "\n",
    "    P_SPAM[word] = SPAM_col[word]/SPAM_word_count\n",
    "    P_not_SPAM[word] = NOT_SPAM_col[word]/NOT_SPAM_word_count\n",
    "    \n",
    "    if label == SPAM:\n",
    "        return P_SPAM[word]\n",
    "    else:\n",
    "        return P_not_SPAM[word]\n",
    "\n",
    "    \n",
    "def calculate_P_B_A(text, label):\n",
    "    P = 1\n",
    "    for i in text.lower().split():\n",
    "        if len(i)>=min_word_len:\n",
    "            P *= calculate_P_Bi_A(i,label)\n",
    "    \n",
    "    if label == SPAM:\n",
    "        return P*P_All_SPAM\n",
    "    else:\n",
    "        return P*(1-P_All_SPAM)\n",
    "\n",
    "\n",
    "def classify(email):\n",
    "    global SPAM_word_count, NOT_SPAM_word_count\n",
    "    SPAM_word_count = sum(SPAM_col.values())\n",
    "    NOT_SPAM_word_count = sum(NOT_SPAM_col.values())\n",
    "    email = dels(email)\n",
    "    \n",
    "    if calculate_P_B_A(email,SPAM) > calculate_P_B_A(email,NOT_SPAM):\n",
    "        return SPAM_DICT[SPAM]\n",
    "    else:\n",
    "        return SPAM_DICT[NOT_SPAM]  \n",
    "    \n",
    "def classify_(email):\n",
    "    global SPAM_word_count, NOT_SPAM_word_count\n",
    "    SPAM_word_count = sum(SPAM_col.values())\n",
    "    NOT_SPAM_word_count = sum(NOT_SPAM_col.values())\n",
    "    email = dels(email)\n",
    "    \n",
    "    if calculate_P_B_A(email,SPAM) > calculate_P_B_A(email,NOT_SPAM):\n",
    "        return SPAM\n",
    "    else:\n",
    "        return NOT_SPAM\n",
    "    \n",
    "def train_all():\n",
    "    global df\n",
    "   \n",
    "    df = pd.read_csv('spam_or_not_spam.zip')\n",
    "    df = df.dropna()\n",
    "    df['label'] = df['label'].apply(lambda s: SPAM if (s == 1) else NOT_SPAM)\n",
    "    df['email'] = df['email'].apply(lambda x: dels(x))\n",
    "    train_data_en = df.values.tolist()\n",
    "       \n",
    "    train(train_data)\n",
    "    train(train_data2)    \n",
    "    train(train_data_en)\n",
    "\n",
    "train_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 462   37]\n",
      " [  19 2481]]\n",
      "0.9888401753686729\n"
     ]
    }
   ],
   "source": [
    "df['label_pred'] = df.email.apply(lambda x: classify_(x))\n",
    "print(confusion_matrix(df['label'],df['label_pred']))\n",
    "print(f1_score(df['label'],df['label_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT SPAM\n",
      "SPAM\n",
      "SPAM\n"
     ]
    }
   ],
   "source": [
    "print(classify(\"Развивай бизнес на дому с услугой 'Безлимитный Интернет\"))\n",
    "print(classify(\"Мы получили ваше сообщение о пропаже багажа и домашнего питомца в здании аэропорта. Конечно, нам жаль. Но что мы можем с этим сделать?\"))\n",
    "print(classify(\"Перезвони по номеру +799999999 в течение 6 секунд и выиграй миллион рублей!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT SPAM\n",
      "NOT SPAM\n",
      "NOT SPAM\n"
     ]
    }
   ],
   "source": [
    "leter1 = \"Hi, My name is Warren E. Buffett an American business magnate, investor and philanthropist. am the most successful investor in the world. I believe strongly in‘giving while living’ I had one idea that never changed in my mind? that you should use your wealth to help people and i have decided to give {$1,500,000.00} One Million Five Hundred Thousand United Dollars, to randomly selected individuals worldwide. On receipt of this email, you should count yourself as the lucky individual. Your email address was chosen online while searching at random. Kindly get back to me at your earliest convenience before i travel to japan for my treatment , so I know your email address is valid. Thank you for accepting our offer, we are indeed grateful You Can Google my name for more information: God bless you. Best Regard Mr.Warren E. Buffett Billionaire investor !\"\n",
    "leter2 = \"Hi guys I want to build a website like REDACTED and I wanted to get your perspective of whether that site is good from the users' perspective before I go ahead and build something similar. I think that the design of the site is very modern and nice but I am not sure how people would react to a similar site? I look forward to your feedback. Many thanks!\"\n",
    "leter3 = \"As a result of your application for the position of Data Engineer, I would like to invite you to attend an interview on May 30, at 9 a.m. at our office in Washington, DC. You will have an interview with the department manager, Moris Peterson. The interview will last about 45 minutes. If the date or time of the interview is inconvenient, please contact me by phone or email to arrange another appointment. We look forward to seeing you.\"\n",
    "print(classify(leter1))\n",
    "print(classify(leter2))\n",
    "print(classify(leter3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
